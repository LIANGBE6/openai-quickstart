{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e2458f-d038-4845-93a0-d4ad830f9f90",
   "metadata": {},
   "source": [
    "# LangChain 核心模块学习：Chains\n",
    "\n",
    "对于简单的大模型应用，单独使用语言模型（LLMs）是可以的。\n",
    "\n",
    "**但更复杂的大模型应用需要将 `LLMs` 和 `Chat Models` 链接在一起 - 要么彼此链接，要么与其他组件链接。**\n",
    "\n",
    "LangChain 为这种“链式”应用程序提供了 `Chain` 接口。\n",
    "\n",
    "LangChain 以通用方式定义了 `Chain`，它是对组件进行调用序列的集合，其中可以包含其他链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24efe291-8745-4e78-bdb4-648e60d7bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
      "  Downloading langchain_core-0.2.22-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.32.2)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp312-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "     ----------------------- ---------------- 30.7/51.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.6/51.6 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
      "   ---------------------------------------- 0.0/990.0 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/990.0 kB 991.0 kB/s eta 0:00:01\n",
      "   --- ------------------------------------ 92.2/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 92.2/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ------ ------------------------------- 174.1/990.0 kB 952.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------ 204.8/990.0 kB 958.4 kB/s eta 0:00:01\n",
      "   --------- ------------------------------ 245.8/990.0 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 337.9/990.0 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------- ----------------------- 368.6/990.0 kB 995.6 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 419.8/990.0 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 481.3/990.0 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 563.2/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 563.2/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 665.6/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 675.8/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 809.0/990.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 860.2/990.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 890.9/990.0 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 962.6/990.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 990.0/990.0 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "   ---------------------------------------- 0.0/369.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/369.0 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/369.0 kB 3.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 143.4/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 143.4/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 225.3/369.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/369.0 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- 369.0/369.0 kB 717.5 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
      "   ---------------------------------------- 0.0/373.5 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/373.5 kB 660.6 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 41.0/373.5 kB 495.5 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 112.6/373.5 kB 819.2 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 174.1/373.5 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 245.8/373.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 297.0/373.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/373.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 348.2/373.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 373.5/373.5 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/139.8 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 61.4/139.8 kB 812.7 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 92.2/139.8 kB 744.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 139.8/139.8 kB 825.3 kB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading SQLAlchemy-2.0.31-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.7/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.7/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 71.7/293.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 92.2/293.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 143.4/293.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 174.1/293.6 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  286.7/293.6 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 293.6/293.6 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading orjson-3.10.6-cp312-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 61.4/136.4 kB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 92.2/136.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.4/136.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 51.2/76.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.4/76.4 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tenacity, orjson, numpy, multidict, jsonpointer, greenlet, frozenlist, yarl, SQLAlchemy, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 multidict-6.0.5 numpy-1.26.4 orjson-3.10.6 tenacity-8.5.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a7df0-26c7-4eb8-92f1-cc54445cf507",
   "metadata": {},
   "source": [
    "## LLMChain\n",
    "\n",
    "LLMChain 是 LangChain 中最简单的链，作为其他复杂 Chains 和 Agents 的内部调用，被广泛应用。\n",
    "\n",
    "一个LLMChain由PromptTemplate和语言模型（LLM or Chat Model）组成。它使用直接传入（或 memory 提供）的 key-value 来规范化生成 Prompt Template（提示模板），并将生成的 prompt （格式化后的字符串）传递给大模型，并返回大模型输出。\n",
    "\n",
    "![](../images/llm_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd5ca7-ca54-4701-919c-2857266caefc",
   "metadata": {},
   "source": [
    "## Router Chain: 实现条件判断的大模型调用\n",
    "\n",
    "\n",
    "这段代码构建了一个可定制的链路系统，用户可以提供不同的输入提示，并根据这些提示获取适当的响应。\n",
    "\n",
    "主要逻辑：从`prompt_infos`创建多个`LLMChain`对象，并将它们保存在一个字典中，然后创建一个默认的`ConversationChain`，最后创建一个带有路由功能的`MultiPromptChain`。\n",
    "\n",
    "![](../images/router_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e508ee-2e88-4e8f-815d-9c9612ff4c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.20 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain_openai) (0.2.22)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain_openai) (1.36.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.11.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 675.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_openai) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.20->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.20->langchain_openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\langchain\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.7 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 30.7/46.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.7/46.7 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/799.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/799.3 kB 3.2 MB/s eta 0:00:01\n",
      "   --- ----------------------------------- 71.7/799.3 kB 787.7 kB/s eta 0:00:01\n",
      "   ------- -------------------------------- 153.6/799.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 204.8/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 307.2/799.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 358.4/799.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 399.4/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 450.6/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 481.3/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 563.2/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 604.2/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 665.6/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 727.0/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 778.2/799.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 799.3/799.3 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/268.5 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 61.4/268.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 112.6/268.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 163.8/268.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 204.8/268.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.5/268.5 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken, langchain_openai\n",
      "Successfully installed langchain_openai-0.1.17 regex-2024.5.15 tiktoken-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf8c391-9225-4e66-ad4d-d689b53a0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acba158b-399c-441a-a8a0-0cd04f46dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "base_url = os.getenv('BASE_URL')\n",
    "api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b5061c-391e-4762-91c7-73b57f4ab501",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\n",
    "你擅长以简洁易懂的方式回答关于物理的问题。\n",
    "当你不知道某个问题的答案时，你会坦诚承认。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"你是一位很棒的数学家。你擅长回答数学问题。\n",
    "之所以如此出色，是因为你能够将难题分解成各个组成部分，\n",
    "先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "biology_template = \"\"\"你是一位很棒的生物学老师。你擅长回答生物学问题。\n",
    "之所以如此出色，是因为你能够将复杂的概念分解成各个组成部分，\n",
    "先解释这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computer_template = \"\"\"你是一位很棒的计算机老师。你擅长回答计算机相关的问题。\n",
    "之所以如此出色，是因为你能够将复杂的问题分解成各个组成部分，\n",
    "先解释这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "chinese_template = \"\"\"你是一位很棒的语文老师。你擅长回答语文相关的问题。\n",
    "之所以如此出色，是因为你能够将复杂的问题分解成各个组成部分，\n",
    "先解释这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ef1db6e-3da4-4f9b-9707-0f30aa293dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"物理\",\n",
    "        \"description\": \"适用于回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"数学\",\n",
    "        \"description\": \"适用于回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"生物\",\n",
    "        \"description\": \"适用于回答生物学问题\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"计算机\",\n",
    "        \"description\": \"适用于回答计算机问题\",\n",
    "        \"prompt_template\": computer_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"汉语言\",\n",
    "        \"description\": \"适用于回答汉语言问题\",\n",
    "        \"prompt_template\": chinese_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3983cafe-c2d5-4951-b779-88d844594777",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db8be9f0-1ac2-4ded-8950-6403cfa40004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "destination_chains = {}\n",
    "\n",
    "# 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]  # 提取名称\n",
    "    prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "    # 创建PromptTemplate对象\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    # 使用上述模板和llm对象创建LLMChain对象\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # 将新创建的chain对象添加到destination_chains字典中\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 创建一个默认的ConversationChain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae77b13a-2077-4e80-83f9-a2b1d8398461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chains.conversation.base.ConversationChain"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa4a82-2d96-4124-8896-4e11e5d5c8e9",
   "metadata": {},
   "source": [
    "### 使用 LLMRouterChain 实现条件判断调用\n",
    "\n",
    "这段代码定义了一个chain对象（LLMRouterChain），该对象首先使用router_chain来决定哪个destination_chain应该被执行，如果没有合适的目标链，则默认使用default_chain。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c196e6c-e767-4d4f-8327-50ead641bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5ada86e-e430-412c-828d-b053b630f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "# 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "# 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# 创建路由的PromptTemplate\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c1013dc-ae1f-468d-96b3-4babe0d50d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['物理: 适用于回答物理问题', '数学: 适用于回答数学问题', '生物: 适用于回答生物学问题', '计算机: 适用于回答计算机问题', '汉语言: 适用于回答汉语言问题']\n"
     ]
    }
   ],
   "source": [
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a85ef126-aca1-40c2-8e01-d15af5500785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言: 适用于回答汉语言问题\n"
     ]
    }
   ],
   "source": [
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5db81fcb-704a-4250-a6b5-210e4be77af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f882244c-1fa6-4d74-a44c-578c9fb25e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言: 适用于回答汉语言问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2a482e4-5757-4295-a3d8-c3fdd1d4abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "128bb7a0-b176-4b14-835e-8aaa723ab441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "物理: {'input': '黑体辐射是什么？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '黑体辐射是什么？', 'text': '\\n\\n黑体辐射是指一个完美吸收所有光波的物体，在一定温度下会发出特定的光谱分布的电磁辐射。它是理想化的概念，用来研究热辐射的特性。'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"黑体辐射是什么？?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd869807-9cec-4bb2-9104-ecc4efce9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "数学: {'input': 'What is the first prime number greater than 40 that is one more than a multiple of 3?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the first prime number greater than 40 that is one more than a multiple of 3?', 'text': '\\n\\n第一个大于40且比3的倍数多1的质数是43。'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"大于40的第一个质数是多少，使得这个质数加一能被3整除？\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ad5dcb2-48c0-4d0f-b6cc-09ebcbdce75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd37e004-bb24-4929-992c-34407593d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "物理: {'input': '什么是黑洞？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '什么是黑洞？', 'text': '\\n\\n黑洞是宇宙中一种非常特殊的天体，它具有非常强大的引力，甚至连光都无法逃离它的吸引力。它的形成是由于质量非常大的恒星在死亡时发生的坍缩，形成一个非常紧密且密度极高的物体。黑洞的边界称为“事件视界”，在这个边界内的一切事物，包括光，都会被吸入黑洞。因为黑洞无法被直接观测到，所以我们只能通过观测其周围物质运动和辐射来推测其存在。黑洞是宇宙中最神秘和具有挑战性的物体之一，它们也是研究宇宙和宇宙规律的重要对象。'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"黑洞是什么？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51119ed-025f-48d7-ad81-cd9cdab7090f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda2930-a0e6-48b2-8e02-4c3d792f0225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d11e0f-d5ee-4086-9e1a-b21000232134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6836f0-213d-4cac-abc9-3617831be3db",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "#### 扩展 Demo：实现生物、计算机和汉语言文学老师 PromptTemplates 及对应 Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c7edb0a-675d-40c0-9f5d-d58f0170ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "生物: {'input': '细胞核是什么？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '细胞核是什么？', 'text': '\\n\\n细胞核是细胞内的一个重要结构，它是一个膜包裹的细胞器官，包含着细胞的遗传物质DNA。细胞核的主要功能是控制细胞的生长、分裂和遗传信息的传递。它还通过调控基因表达来控制细胞的特征和功能。细胞核内还含有核糖核蛋白颗粒，参与蛋白质的合成。细胞核的结构和功能对细胞的生存和繁殖至关重要。'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"细胞核是什么？\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42cca895-7c19-47ba-a034-ff4fcd0c92f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "计算机: {'input': '计算机组成原理学科有什么概念？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '计算机组成原理学科有什么概念？', 'text': '\\n计算机组成原理是计算机科学的一门基础学科，它研究计算机系统的设计、构建和运行原理。它涉及到计算机硬件、软件以及它们之间的交互关系。主要包括以下几个概念：\\n\\n1. 计算机体系结构：指的是计算机硬件和软件之间的交互结构，包括处理器、存储器、输入输出设备以及系统总线等组件。\\n\\n2. 计算机指令集架构：指的是计算机系统的指令集合，包括指令的格式、指令的功能和计算机执行指令的方式等。\\n\\n3. 计算机中央处理器（CPU）：是计算机的核心部件，负责执行指令、控制计算机的操作和处理数据。\\n\\n4. 存储器：是计算机中'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"计算机组成原理学科有什么概念？\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4225d21a-c87f-48b7-84d8-04d786ba414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "汉语言: {'input': '李白是谁'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '李白是谁', 'text': '？\\n\\n解答：\\n李白是中国唐代伟大的诗人，被称为“诗仙”。他的诗歌风格豪放、奔放，充满着对自然和生活的热爱。他的诗作受到广泛的欢迎和赞赏，被人们称为“李白诗风”。他的代表作品有《静夜思》、《蜀道难》等。他的诗歌成为了中国古典文学中不可或缺的一部分，对后世诗人也有深远的影响。'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"在古诗词中李白是谁\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
